{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xj13XOYF_hgl",
        "PyVgEvM0_lZJ",
        "UGWRBZ81fTtL"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcAAObid/2UCuPQ2ca05ns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luca4Spreafico/CHALLENGE-2---Ibuprofen/blob/main/Luca_Ibuprofen2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒ **Kaggle setup**"
      ],
      "metadata": {
        "id": "xj13XOYF_hgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir = \"/kaggle/working\"\n",
        "input_dir = \"/kaggle/input\"\n",
        "dataset_dir = \"/kaggle/input\""
      ],
      "metadata": {
        "id": "hD03ethf_eCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒ **Google Drive setup**"
      ],
      "metadata": {
        "id": "PyVgEvM0_lZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ___________________________________________________________________________________ collegamento colab\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")\n",
        "working_dir = \"/gdrive/My Drive/B University/Artificial Networks/an2dl2526c2\"\n",
        "input_dir = working_dir\n",
        "\n",
        "%cd $working_dir\n",
        "\n",
        "print(f\"Working at folder: {working_dir}\")\n",
        "print(f\"Input at folder: {input_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxB0Ktup_mzk",
        "outputId": "0e3163d8-2d3b-4728-be83-5694e88692d8",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/B University/Artificial Networks/an2dl2526c2\n",
            "Working at folder: /gdrive/My Drive/B University/Artificial Networks/an2dl2526c2\n",
            "Input at folder: /gdrive/My Drive/B University/Artificial Networks/an2dl2526c2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "BxT78ZTMv_Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ___________________________________________________________________________________ Libraries\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Configurazione di TensorBoard e directory\n",
        "logs_dir = \"tensorboard\"\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p models\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0bvaI3dwDAw",
        "outputId": "2cc339bd-1f5e-46cc-ff06-dc67fe9d75d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading"
      ],
      "metadata": {
        "id": "dEaoz1SI4te4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# _________________________________________  DATA LOADING\n",
        "\n",
        "dataset_dir = input_dir   # adjust to your real folder\n",
        "\n",
        "train_data_dir = os.path.join(dataset_dir, \"train_data\")\n",
        "train_labels_path = os.path.join(dataset_dir, \"train_labels.csv\")\n",
        "\n",
        "\n",
        "# ------------------ Check directories (FAIL-FAST) ------------------\n",
        "print(\"Validating dataset structure...\")\n",
        "\n",
        "# Check training directory - CRITICAL\n",
        "if not os.path.exists(train_data_dir):\n",
        "    raise FileNotFoundError(f\"CRITICAL ERROR: Training data folder not found at: {train_data_dir}\")\n",
        "print(f\"âœ“ Training folder found: {train_data_dir}\")\n",
        "\n",
        "# ------------------ Check labels file (FAIL-FAST) ------------------\n",
        "if not os.path.exists(train_labels_path):\n",
        "    raise FileNotFoundError(f\"CRITICAL ERROR: train_labels.csv not found at: {train_labels_path}\")\n",
        "print(f\"âœ“ Labels file found: {train_labels_path}\")\n",
        "\n",
        "# ------------------ Load labels (FAIL-FAST) ------------------\n",
        "try:\n",
        "    df_labels = pd.read_csv(train_labels_path)\n",
        "    print(f\"âœ“ Loaded {len(df_labels)} training labels.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"CRITICAL ERROR: Failed to load labels file: {e}\")\n",
        "\n",
        "# Validate that labels DataFrame is not empty\n",
        "if len(df_labels) == 0:\n",
        "    raise ValueError(\"CRITICAL ERROR: Labels file is empty!\")\n",
        "\n",
        "# Validate that 'label' column exists\n",
        "if 'label' not in df_labels.columns:\n",
        "    raise ValueError(f\"CRITICAL ERROR: 'label' column not found in CSV. Available columns: {df_labels.columns.tolist()}\")\n",
        "\n",
        "# ------------------ Load training images & masks ------------------\n",
        "print(\"\\nLoading training images and masksâ€¦\")\n",
        "\n",
        "file_list = sorted(os.listdir(train_data_dir))\n",
        "N = len(df_labels)  # should be 1412\n",
        "\n",
        "# FAIL-FAST: Check expected file count\n",
        "if len(file_list) != 2 * N:\n",
        "    raise ValueError(f\"CRITICAL ERROR: Expected {2*N} files, found {len(file_list)}. Dataset is incomplete!\")\n",
        "\n",
        "# First half = images\n",
        "image_files = file_list[:N]\n",
        "\n",
        "# Second half = masks\n",
        "mask_files = file_list[N:N*2]\n",
        "\n",
        "# Initialize lists to store loaded data as numpy arrays\n",
        "train_images = []      # List of numpy arrays (variable dimensions)\n",
        "train_masks = []       # List of numpy arrays (variable dimensions)\n",
        "train_targets = []     # List of labels\n",
        "train_dimensions = []  # List to track (height, width) of each sample\n",
        "\n",
        "# Track validation issues\n",
        "failed_samples = []\n",
        "dimension_mismatches = []\n",
        "\n",
        "# Define label encoding\n",
        "label_mapping = {\n",
        "      'Luminal A': 0,\n",
        "      'Luminal B': 1,\n",
        "      'HER2(+)': 2,\n",
        "      'Triple negative': 3\n",
        "  }\n",
        "\n",
        "# Iterate through each row in the labels DataFrame\n",
        "for idx, row in df_labels.iterrows():\n",
        "    filename_img  = image_files[idx]\n",
        "    filename_mask = mask_files[idx]\n",
        "    label         = row[\"label\"]\n",
        "\n",
        "    img_path  = os.path.join(train_data_dir, filename_img)\n",
        "    mask_path = os.path.join(train_data_dir, filename_mask)\n",
        "\n",
        "    try:\n",
        "        # Open image and mask\n",
        "        img  = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # Convert to numpy arrays immediately for memory efficiency\n",
        "        img_array = np.array(img)    # Shape: (H, W, 3)\n",
        "        mask_array = np.array(mask)  # Shape: (H, W)\n",
        "\n",
        "        # VALIDATION: Check that image and mask have matching dimensions\n",
        "        if img_array.shape[:2] != mask_array.shape:\n",
        "            dimension_mismatches.append({\n",
        "                'index': idx,\n",
        "                'filename_img': filename_img,\n",
        "                'filename_mask': filename_mask,\n",
        "                'img_shape': img_array.shape,\n",
        "                'mask_shape': mask_array.shape\n",
        "            })\n",
        "            print(f\"WARNING: Dimension mismatch at index {idx}: image {img_array.shape} vs mask {mask_array.shape}\")\n",
        "            continue  # Skip this sample\n",
        "\n",
        "        # Encode the label\n",
        "        encoded_label = label_mapping[label]\n",
        "\n",
        "        # Store numpy arrays instead of PIL images\n",
        "        train_images.append(img_array)\n",
        "        train_masks.append(mask_array)\n",
        "        train_targets.append(encoded_label)  # Store encoded label instead\n",
        "        train_dimensions.append(img_array.shape[:2])\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_samples.append({'index': idx, 'error': str(e)})\n",
        "        print(f\"ERROR loading sample index {idx}: {e}\")\n",
        "\n",
        "print(f\"\\nâœ“ Successfully loaded {len(train_images)} training samples.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ VALIDATION REPORT ------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Report failed samples\n",
        "if failed_samples:\n",
        "    print(f\"\\nâš  WARNING: {len(failed_samples)} samples failed to load:\")\n",
        "    for fail in failed_samples[:5]:  # Show first 5\n",
        "        print(f\"  - Index {fail['index']}: {fail['error']}\")\n",
        "    if len(failed_samples) > 5:\n",
        "        print(f\"  ... and {len(failed_samples) - 5} more\")\n",
        "\n",
        "# Report dimension mismatches\n",
        "if dimension_mismatches:\n",
        "    print(f\"\\nâš  WARNING: {len(dimension_mismatches)} samples had dimension mismatches:\")\n",
        "    for mismatch in dimension_mismatches[:5]:  # Show first 5\n",
        "        print(f\"  - Index {mismatch['index']}: img {mismatch['img_shape']} vs mask {mismatch['mask_shape']}\")\n",
        "    if len(dimension_mismatches) > 5:\n",
        "        print(f\"  ... and {len(dimension_mismatches) - 5} more\")\n",
        "\n",
        "# Check if too many samples failed\n",
        "total_failed = len(failed_samples) + len(dimension_mismatches)\n",
        "if total_failed > N * 0.05:  # More than 5% failed\n",
        "    raise RuntimeError(f\"CRITICAL ERROR: Too many samples failed ({total_failed}/{N}). Dataset quality is too low!\")\n",
        "\n",
        "# Validate label distribution\n",
        "print(f\"\\nLabel distribution:\")\n",
        "unique_labels, counts = np.unique(train_targets, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"  Label {label}: {count} samples ({100*count/len(train_targets):.1f}%)\")\n",
        "\n",
        "# Display dimension statistics\n",
        "print(f\"\\nImage dimension statistics:\")\n",
        "heights = [dim[0] for dim in train_dimensions]\n",
        "widths = [dim[1] for dim in train_dimensions]\n",
        "print(f\"  Height range: {min(heights)} - {max(heights)} pixels (mean: {np.mean(heights):.1f})\")\n",
        "print(f\"  Width range: {min(widths)} - {max(widths)} pixels (mean: {np.mean(widths):.1f})\")\n",
        "\n",
        "# Count unique dimensions\n",
        "unique_dims = set(train_dimensions)\n",
        "print(f\"  Number of unique dimension combinations: {len(unique_dims)}\")\n",
        "if len(unique_dims) <= 5:\n",
        "    print(f\"  Unique dimensions found:\")\n",
        "    for dim in sorted(unique_dims):\n",
        "        count = train_dimensions.count(dim)\n",
        "        print(f\"    - {dim}: {count} samples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ“ Training data validation complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoEeOSA0HwJN",
        "outputId": "34dd72ef-9b3a-4490-fc81-3fde30458850"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating dataset structure...\n",
            "âœ“ Training folder found: /gdrive/My Drive/B University/Artificial Networks/an2dl2526c2/train_data\n",
            "âœ“ Labels file found: /gdrive/My Drive/B University/Artificial Networks/an2dl2526c2/train_labels.csv\n",
            "âœ“ Loaded 1412 training labels.\n",
            "\n",
            "Loading training images and masksâ€¦\n",
            "\n",
            "âœ“ Successfully loaded 1412 training samples.\n",
            "\n",
            "============================================================\n",
            "VALIDATION REPORT\n",
            "============================================================\n",
            "\n",
            "Label distribution:\n",
            "  Label 0: 414 samples (29.3%)\n",
            "  Label 1: 445 samples (31.5%)\n",
            "  Label 2: 397 samples (28.1%)\n",
            "  Label 3: 156 samples (11.0%)\n",
            "\n",
            "Image dimension statistics:\n",
            "  Height range: 1024 - 4233 pixels (mean: 1341.4)\n",
            "  Width range: 1024 - 3970 pixels (mean: 1252.3)\n",
            "  Number of unique dimension combinations: 639\n",
            "\n",
            "============================================================\n",
            "âœ“ Training data validation complete!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Improvements:\n",
        "\n",
        "Label Encoding: Converts text labels (Luminal A, Luminal B, etc.) to numeric values needed for CNN training\n",
        "Image Size Analysis: Tracks and reports image dimensions to help you choose an appropriate target size\n",
        "Preprocessing Function:\n",
        "\n",
        "Resizes all images to a uniform size (necessary for CNNs)\n",
        "Normalizes pixel values to [0, 1] range\n",
        "Optionally applies masks to focus on diseased tissue regions\n",
        "Returns numpy arrays ready for training\n",
        "\n",
        "\n",
        "Train/Validation Split: Creates a validation set (20%) while maintaining class distribution for proper model evaluation\n",
        "Data Shapes: Reports shapes to verify everything is ready for CNN input"
      ],
      "metadata": {
        "id": "5N2x9v95Vlzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalization**\n",
        "\n",
        "- Neural networks train better with smaller numbers (typically -1 to +1 or 0 to 1).\n",
        "\n",
        "- Prevents numerical instability - large values (255) can cause gradient explosions.\n",
        "\n",
        "- Standard practice - most pre-trained models expect normalized inputs\n",
        "Faster convergence - optimization algorithms work better.\n"
      ],
      "metadata": {
        "id": "WpCZ9H83eaCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "UGWRBZ81fTtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Load test images (NO LABELS) ------------------\n",
        "print(\"\\nLoading test images...\")\n",
        "dataset_dir = input_dir\n",
        "test_data_dir  = os.path.join(dataset_dir, \"test_data\")\n",
        "\n",
        "# Check test directory - CRITICAL\n",
        "if not os.path.exists(test_data_dir):\n",
        "    raise FileNotFoundError(f\"CRITICAL ERROR: Test data folder not found at: {test_data_dir}\")\n",
        "print(f\"âœ“ Test folder found: {test_data_dir}\")\n",
        "\n",
        "\n",
        "test_file_list = sorted(os.listdir(test_data_dir))\n",
        "N = len(test_file_list) // 2  # should be 954\n",
        "\n",
        "\n",
        "# FAIL-FAST: Check expected file count\n",
        "if len(test_file_list) != 1908:\n",
        "    raise ValueError(f\"CRITICAL ERROR: Expected {1908} files, found {len(test_file_list)}. Test Dataset is incomplete!\")\n",
        "\n",
        "# First half = images\n",
        "test_image_files = test_file_list[:N]\n",
        "\n",
        "# Second half = masks\n",
        "test_mask_files = test_file_list[N:N*2]\n",
        "\n",
        "# Initialize lists to store loaded data as numpy arrays\n",
        "test_images = []      # List of numpy arrays (variable dimensions)\n",
        "test_masks = []       # List of numpy arrays (variable dimensions)\n",
        "test_dimensions = []  # List to track (height, width) of each sample\n",
        "\n",
        "# Track validation issues\n",
        "failed_samples = []\n",
        "dimension_mismatches = []\n",
        "\n",
        "\n",
        "# Iterate through each row in the labels DataFrame\n",
        "for idx in range(N):\n",
        "    test_filename_img  = test_image_files[idx]\n",
        "    test_filename_mask = test_mask_files[idx]\n",
        "\n",
        "    test_img_path  = os.path.join(test_data_dir, test_filename_img)\n",
        "    test_mask_path = os.path.join(test_data_dir, test_filename_mask)\n",
        "\n",
        "    try:\n",
        "        # Open image and mask\n",
        "        test_img  = Image.open(test_img_path).convert(\"RGB\")\n",
        "        test_mask = Image.open(test_mask_path).convert(\"L\")\n",
        "\n",
        "        # Convert to numpy arrays immediately for memory efficiency\n",
        "        test_img_array = np.array(test_img)    # Shape: (H, W, 3)\n",
        "        test_mask_array = np.array(test_mask)  # Shape: (H, W)\n",
        "\n",
        "        # VALIDATION: Check that image and mask have matching dimensions\n",
        "        if test_img_array.shape[:2] != test_mask_array.shape:\n",
        "            dimension_mismatches.append({\n",
        "                'index': idx,\n",
        "                'filename_img': test_filename_img,\n",
        "                'filename_mask': test_filename_mask,\n",
        "                'img_shape': test_img_array.shape,\n",
        "                'mask_shape': test_mask_array.shape\n",
        "            })\n",
        "            print(f\"WARNING: Dimension mismatch at index {idx}: image {test_img_array.shape} vs mask {test_mask_array.shape}\")\n",
        "            continue  # Skip this sample\n",
        "\n",
        "\n",
        "        # Store numpy arrays instead of PIL images\n",
        "        test_images.append(test_img_array)\n",
        "        test_masks.append(test_mask_array)\n",
        "        test_dimensions.append(test_img_array.shape[:2])\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_samples.append({'index': idx, 'error': str(e)})\n",
        "        print(f\"ERROR loading sample index {idx}: {e}\")\n",
        "\n",
        "print(f\"\\nâœ“ Successfully loaded {len(test_images)} test samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TaLSSP6IfQdC",
        "outputId": "4a74ccd2-5c2e-4eee-9c29-cb7bd7d08bd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading test images...\n",
            "âœ“ Test folder found: /gdrive/My Drive/B University/Artificial Networks/an2dl2526c2/test_data\n",
            "\n",
            "âœ“ Successfully loaded 954 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ VALIDATION REPORT ------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Report failed samples\n",
        "if failed_samples:\n",
        "    print(f\"\\nâš  WARNING: {len(failed_samples)} samples failed to load:\")\n",
        "    for fail in failed_samples[:5]:  # Show first 5\n",
        "        print(f\"  - Index {fail['index']}: {fail['error']}\")\n",
        "    if len(failed_samples) > 5:\n",
        "        print(f\"  ... and {len(failed_samples) - 5} more\")\n",
        "\n",
        "# Report dimension mismatches\n",
        "if dimension_mismatches:\n",
        "    print(f\"\\nâš  WARNING: {len(dimension_mismatches)} samples had dimension mismatches:\")\n",
        "    for mismatch in dimension_mismatches[:5]:  # Show first 5\n",
        "        print(f\"  - Index {mismatch['index']}: img {mismatch['img_shape']} vs mask {mismatch['mask_shape']}\")\n",
        "    if len(dimension_mismatches) > 5:\n",
        "        print(f\"  ... and {len(dimension_mismatches) - 5} more\")\n",
        "\n",
        "# Check if too many samples failed\n",
        "total_failed = len(failed_samples) + len(dimension_mismatches)\n",
        "if total_failed > N * 0.05:  # More than 5% failed\n",
        "    raise RuntimeError(f\"CRITICAL ERROR: Too many samples failed ({total_failed}/{N}). Dataset quality is too low!\")\n",
        "\n",
        "\n",
        "# Display dimension statistics\n",
        "print(f\"\\nImage dimension statistics:\")\n",
        "heights = [dim[0] for dim in test_dimensions]\n",
        "widths = [dim[1] for dim in test_dimensions]\n",
        "print(f\"  Height range: {min(heights)} - {max(heights)} pixels (mean: {np.mean(heights):.1f})\")\n",
        "print(f\"  Width range: {min(widths)} - {max(widths)} pixels (mean: {np.mean(widths):.1f})\")\n",
        "\n",
        "# Count unique dimensions\n",
        "unique_dims = set(test_dimensions)\n",
        "print(f\"  Number of unique dimension combinations: {len(unique_dims)}\")\n",
        "if len(unique_dims) <= 5:\n",
        "    print(f\"  Unique dimensions found:\")\n",
        "    for dim in sorted(unique_dims):\n",
        "        count = test_dimensions.count(dim)\n",
        "        print(f\"    - {dim}: {count} samples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ“ Training data validation complete!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeToAfLk6lYX",
        "outputId": "659252b8-96e3-4df4-ac6f-5c984cd08604"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "VALIDATION REPORT\n",
            "============================================================\n",
            "\n",
            "Image dimension statistics:\n",
            "  Height range: 1024 - 4752 pixels (mean: 1323.4)\n",
            "  Width range: 1024 - 6158 pixels (mean: 1271.3)\n",
            "  Number of unique dimension combinations: 544\n",
            "\n",
            "============================================================\n",
            "âœ“ Training data validation complete!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}